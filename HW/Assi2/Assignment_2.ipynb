{
 "metadata": {
  "name": "",
  "signature": "sha256:01961281365ce2e42b0e87b4acea7f01efa82814b3fc51969a2edb0c49a7ecbf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1. K-Nearest-Neighbor (KNN) classification on Newsgroup"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from numpy import *\n",
      "import numpy as np\n",
      "import operator\n",
      "np.set_printoptions(precision=2,suppress=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "1a. Create your own KNN classifier"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def knn_classify(x, D, L, K, measure):\n",
      "    if measure == 0: # euclidean\n",
      "        dists = sqrt(((D - x)**2).sum(axis=1))\n",
      "    elif measure == 1: # cosine\n",
      "        D_norm = array([linalg.norm(D[i]) for i in range(len(D))])\n",
      "        x_norm = linalg.norm(x)\n",
      "        cosines = dot(D,x)/(D_norm * x_norm)\n",
      "        dists = 1 - cosines\n",
      "    idx = argsort(dists)\n",
      "    count={}          \n",
      "    for i in range(K):\n",
      "        vote = L[idx[i]]\n",
      "        count[vote] = count.get(vote,0) + 1\n",
      "    sortedClass = sorted(count.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
      "    return sortedClass[0][0], idx[:K]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "1b. Create a function to compute the classification accuracy"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def classAccuracy(A, x, D, L, K, measure):\n",
      "    numLabels = len(A)\n",
      "    errorCount = 0.0\n",
      "    for i in range(numLabels):\n",
      "        classifierResult, neigh_idx = knn_classify(x[i,:], D, L, K, measure)\n",
      "        #print \"the classifier result: %s, the real answer is: %s\" % (classifierResult, labels[i])\n",
      "        if (classifierResult != A[i]): errorCount += 1.0\n",
      "    errorRate = errorCount/float(numLabels)\n",
      "    #print \"the total error rate is %f\" % (errorCount/float(numLabels))\n",
      "    #print \"total error: %d/%d\" % (errorCount, numLabels)\n",
      "    return errorRate"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "1c. Run your accuracy function on a range of values for K"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TD = np.genfromtxt('trainMatrixModified.txt',delimiter='\\t',dtype=float)\n",
      "labels = np.genfromtxt('trainClasses.txt',delimiter='\\t',usecols=(1),dtype=int)\n",
      "DT = TD.T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testTD = np.genfromtxt('testMatrixModified.txt',delimiter='\\t',dtype=float)\n",
      "testLabels = np.genfromtxt('testClasses.txt',delimiter='\\t',usecols=(1),dtype=int)\n",
      "testDT = testTD.T"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "result = np.zeros((20,3), dtype=float)\n",
      "for i in range(0,20):\n",
      "    errorRateEuc = classAccuracy(testLabels, testDT, DT, labels, i+1, 0)\n",
      "    errorRateCos = classAccuracy(testLabels, testDT, DT, labels, i+1, 1)\n",
      "    result[i] = [i+1, errorRateEuc, errorRateCos]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Nomal data set\"\n",
      "print \" K  Euclid  Cosine\"\n",
      "for row in result:\n",
      "    print \"%2.0f   %.2f    %.2f\" % (row[0], row[1], row[2]) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Nomal data set\n",
        " K  Euclid  Cosine\n",
        " 1   0.22    0.01\n",
        " 2   0.21    0.04\n",
        " 3   0.19    0.03\n",
        " 4   0.23    0.04\n",
        " 5   0.18    0.03\n",
        " 6   0.26    0.02\n",
        " 7   0.23    0.02\n",
        " 8   0.27    0.03\n",
        " 9   0.25    0.03\n",
        "10   0.29    0.03\n",
        "11   0.20    0.02\n",
        "12   0.28    0.03\n",
        "13   0.23    0.02\n",
        "14   0.26    0.03\n",
        "15   0.21    0.01\n",
        "16   0.27    0.03\n",
        "17   0.24    0.03\n",
        "18   0.28    0.03\n",
        "19   0.26    0.03\n",
        "20   0.29    0.03\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "1d. Using TFxIDF weights to evaluation on the range of K values"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allTD = np.concatenate((TD, testTD), axis=1)\n",
      "DF = np.array([(allTD!=0).sum(1)]).T\n",
      "NDocs = len(allTD[0,:])\n",
      "NMatrix = np.ones(np.shape(allTD), dtype=float)*NDocs\n",
      "IDF = log2(divide(NMatrix, DF))\n",
      "TD_tfidf = allTD * IDF"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  7.89   0.     0.   ...,   0.     0.     0.  ]\n",
        " [ 14.32   0.     0.   ...,   0.     0.     0.  ]\n",
        " [ 13.01   0.     0.   ...,   0.     0.     0.  ]\n",
        " ..., \n",
        " [  0.     0.     0.   ...,   0.     0.     0.  ]\n",
        " [  0.     0.     0.   ...,   0.     0.     0.  ]\n",
        " [  0.     0.     0.   ...,   0.     0.     0.  ]]\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tpercent = 0.8\n",
      "DT_tfidf = TD_tfidf.T\n",
      "tsize = tpercent * len(DT_tfidf)\n",
      "trainDT_tfidf = DT_tfidf[:tsize,:]\n",
      "testDT_tfidf = DT_tfidf[tsize:,:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TFxIDF = np.zeros((20,3), dtype=float)\n",
      "for i in range(0,20):\n",
      "    errorRateEuc = classAccuracy(testLabels, testDT_tfidf, trainDT_tfidf, labels, i+1, 0)\n",
      "    errorRateCos = classAccuracy(testLabels, testDT_tfidf, trainDT_tfidf, labels, i+1, 1)\n",
      "    #print \"%2d,  %.2f,   %.2f\" % (i, errorRateEuc, errorRateCos)\n",
      "    TFxIDF[i] = [i+1, errorRateEuc, errorRateCos]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"TFxIDF data set\"\n",
      "print \" K  Euclid  Cosine\"\n",
      "for row in TFxIDF:\n",
      "    print \"%2.0f   %.2f    %.2f\" % (row[0], row[1], row[2]) \n",
      "print \"\\nNomal data set\"\n",
      "print \" K  Euclid  Cosine\"\n",
      "for row in result:\n",
      "    print \"%2.0f   %.2f    %.2f\" % (row[0], row[1], row[2]) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "TFxIDF data set\n",
        " K  Euclid  Cosine\n",
        " 1   0.28    0.05\n",
        " 2   0.26    0.04\n",
        " 3   0.26    0.03\n",
        " 4   0.20    0.03\n",
        " 5   0.20    0.03\n",
        " 6   0.29    0.02\n",
        " 7   0.27    0.01\n",
        " 8   0.35    0.01\n",
        " 9   0.31    0.01\n",
        "10   0.38    0.01\n",
        "11   0.32    0.01\n",
        "12   0.39    0.01\n",
        "13   0.35    0.01\n",
        "14   0.41    0.01\n",
        "15   0.40    0.01\n",
        "16   0.41    0.01\n",
        "17   0.41    0.01\n",
        "18   0.43    0.01\n",
        "19   0.37    0.01\n",
        "20   0.41    0.01\n",
        "\n",
        "Nomal data set\n",
        " K  Euclid  Cosine\n",
        " 1   0.22    0.01\n",
        " 2   0.21    0.04\n",
        " 3   0.19    0.03\n",
        " 4   0.23    0.04\n",
        " 5   0.18    0.03\n",
        " 6   0.26    0.02\n",
        " 7   0.23    0.02\n",
        " 8   0.27    0.03\n",
        " 9   0.25    0.03\n",
        "10   0.29    0.03\n",
        "11   0.20    0.02\n",
        "12   0.28    0.03\n",
        "13   0.23    0.02\n",
        "14   0.26    0.03\n",
        "15   0.21    0.01\n",
        "16   0.27    0.03\n",
        "17   0.24    0.03\n",
        "18   0.28    0.03\n",
        "19   0.26    0.03\n",
        "20   0.29    0.03\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "1e. Discuss your observations based on the above experiments"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ans: KNN classifier using cosine gives a better error rate compare to  Euclid. The result from nomal dataset gives a better error rate compare to TFxIDF, but The result from TFxIDF shows a linea relationship between number of K and error rate."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}